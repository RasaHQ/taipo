{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"taipo \u00b6 This app contains tools for data quality in Rasa. It can generate augmented data but it can also check for bad labels in your training data. The hope is this tool contributes to data that leads to more robust models. Feedback on Non-English languages is especially appreciated! Installation \u00b6 You can install this experiment via pip. python -m pip install \"taipo @ git+https://github.com/RasaHQ/taipo.git\" Usage \u00b6 Taipo comes with a small suite of sub-commands. > python -m taipo This app contains tools for data quality in Rasa. It can generate augmented data but it can also check for bad labels. The hope is this tool contributes to data that leads to more robust models. Options: --help Show this message and exit. Commands: confirm Confirms labels via a trained model. keyboard Commands to simulate keyboard typos. translit Commands to generate transliterations. util Some utility commands. Check the quick-start guide for a tutorial on how to use this tool. Main Features \u00b6 Keyboard Typos \u00b6 Check the API docs for more info. Transliteration \u00b6 Check the API docs for more info. Confirmation \u00b6 Check the API docs for more info. What's in the name? \u00b6 taipo is a mispelling of typo, it means evil spirit","title":"Home"},{"location":"#taipo","text":"This app contains tools for data quality in Rasa. It can generate augmented data but it can also check for bad labels in your training data. The hope is this tool contributes to data that leads to more robust models. Feedback on Non-English languages is especially appreciated!","title":"taipo"},{"location":"#installation","text":"You can install this experiment via pip. python -m pip install \"taipo @ git+https://github.com/RasaHQ/taipo.git\"","title":"Installation"},{"location":"#usage","text":"Taipo comes with a small suite of sub-commands. > python -m taipo This app contains tools for data quality in Rasa. It can generate augmented data but it can also check for bad labels. The hope is this tool contributes to data that leads to more robust models. Options: --help Show this message and exit. Commands: confirm Confirms labels via a trained model. keyboard Commands to simulate keyboard typos. translit Commands to generate transliterations. util Some utility commands. Check the quick-start guide for a tutorial on how to use this tool.","title":"Usage"},{"location":"#main-features","text":"","title":"Main Features"},{"location":"#keyboard-typos","text":"Check the API docs for more info.","title":"Keyboard Typos"},{"location":"#transliteration","text":"Check the API docs for more info.","title":"Transliteration"},{"location":"#confirmation","text":"Check the API docs for more info.","title":"Confirmation"},{"location":"#whats-in-the-name","text":"taipo is a mispelling of typo, it means evil spirit","title":"What's in the name?"},{"location":"getting-started/","text":"Getting Started \u00b6 The original goal of taipo was to augment NLU data such that we can train Rasa models to be robust against misspellings. This guide will show you how to train models that are robust against spelling errors. Installation \u00b6 You can install this experiment via pip. python -m pip install \"taipo @ git+https://github.com/RasaHQ/taipo.git\" This will install the taipo command line interface in your virtualenv. You can confirm the installation went fine by running: python -m taipo Generating Spelling Errors \u00b6 Let's say that you've gotten a Rasa project. Your folder structure would look something like: \ud83d\udcc2 rasa-project-dir \u2523\u2501\u2501 \ud83d\udcc2 actions \u2523\u2501\u2501 \ud83d\udcc2 data \u2503 \u2523\u2501\u2501 \ud83d\udcc4 nlu.yml \u2503 \u2523\u2501\u2501 \ud83d\udcc4 rules.yml \u2503 \u2517\u2501\u2501 \ud83d\udcc4 stories.yml \u2523\u2501\u2501 \ud83d\udcc2 models \u2523\u2501\u2501 \ud83d\udcc2 tests \u2523\u2501\u2501 \ud83d\udcc4 config.yml \u2523\u2501\u2501 \ud83d\udcc4 credentials.yml \u2523\u2501\u2501 \ud83d\udcc4 domain.yml \u2517\u2501\u2501 \ud83d\udcc4 endpoints.yml The idea is that we will generate a variant of nlu.yml that contains spelling errors. This way, we might be able to train our models to be robust against it. A straightforward way to do this is via; python -m taipo keyboard augment data/nlu.yml data/typo-nlu.yml This will generate a new file that contains typos. \ud83d\udcc2 rasa-project-dir \u2523\u2501\u2501 \ud83d\udcc2 actions \u2523\u2501\u2501 \ud83d\udcc2 data \u2503 \u2523\u2501\u2501 \ud83d\udcc4 nlu.yml \u2503 \u2523\u2501\u2501 \ud83d\udcc4 typo-nlu.yml \u2503 \u2523\u2501\u2501 \ud83d\udcc4 rules.yml \u2503 \u2517\u2501\u2501 \ud83d\udcc4 stories.yml \u2523\u2501\u2501 \ud83d\udcc2 models \u2523\u2501\u2501 \ud83d\udcc2 tests \u2523\u2501\u2501 \ud83d\udcc4 config.yml \u2523\u2501\u2501 \ud83d\udcc4 credentials.yml \u2523\u2501\u2501 \ud83d\udcc4 domain.yml \u2517\u2501\u2501 \ud83d\udcc4 endpoints.yml When you inspect the typo-nlu.yml file you'll notice that we copied each example from the original nlu.yml file but added some typos. These typos are based on the keyboard layout. The base setting assumes the US layout but you can configure some non-English layouts as well. Check the API docs for more info. When you now train your nlu model, it will also train on these misspelled items. python -m rasa train You will notice that training takes a fair bit longer because we're training on twice as much data now. Finetuning \u00b6 If you're worried about the long training time, you may prefer to use the fine-tuning feature instead. If you're unfamiliar with the technique, you may appreciate this algorithm whiteboard video. To train the system with finetuning you can first train your NLU model on the original data. rasa train nlu --nlu nlu/nlu.yml --fixed-model-name orig Once this model is trained, you can finetune it on the misspelled data. rasa train nlu --nlu nlu/nlu.yml \\ --finetune models/orig.tar.gz \\ --epoch-fraction 0.1 \\ --fixed-model-name finetuned Benchmarking \u00b6 Training against misspelled data is nice, but we'd also like to quantify the effect that typos have on our system. This guide assumes that you have a tests/nlu-valid.yml file which can be used as a validation dataset. Let's make a misspelled variant of this dataset first. python -m taipo keyboard augment tests/nlu-valid.yml tests/typo-nlu-valid.yml We can now run our two models models/orig.tar.gz and models/finetuned.tar.gz against both of these datasets. rasa test nlu -u tests/nlu-valid.yml --model models/orig.tar.gz --out gridresults/orig-model rasa test nlu -u tests/nlu-valid.yml --model models/finetuned.tar.gz --out gridresults/finetuned-model rasa test nlu -u tests/typo-nlu-valid.yml --model models/orig.tar.gz --out gridresults/typo-orig-model rasa test nlu -u tests/typo-nlu-valid.yml --model models/finetuned.tar.gz --out gridresults/typo-finetuned-model This results in 4 folders that contain your benchmarked results. You could use rasalit to visualise these but you can also use a utility function from the command line. Let's say that you've got a folder structure like so: \ud83d\udcc2 gridresults \u2523\u2501\u2501 \ud83d\udcc2 orig-model \u2503 \u2523\u2501\u2501 ... \u2503 \u2517\u2501\u2501 \ud83d\udcc4 intent_report.json \u2523\u2501\u2501 \ud83d\udcc2 finetuned-model \u2503 \u2523\u2501\u2501 ... \u2503 \u2517\u2501\u2501 \ud83d\udcc4 intent_report.json \u2523\u2501\u2501 \ud83d\udcc2 typo-orig-model \u2503 \u2523\u2501\u2501 ... \u2503 \u2517\u2501\u2501 \ud83d\udcc4 intent_report.json \u2517\u2501\u2501 \ud83d\udcc2 typo-finetuned-model \u2523\u2501\u2501 ... \u2517\u2501\u2501 \ud83d\udcc4 intent_report.json Then you can get a convenient summary via: python -m taipo util summary gridresults You may get a table that looks like this: \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 folder \u2503 accuracy \u2503 precision \u2503 recall \u2503 f1 \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 finetuned-model \u2502 0.9022 \u2502 0.90701 \u2502 0.9022 \u2502 0.90265 \u2502 \u2502 orig-model \u2502 0.90018 \u2502 0.90972 \u2502 0.90018 \u2502 0.90192 \u2502 \u2502 typo-finetuned-model \u2502 0.89965 \u2502 0.90302 \u2502 0.89965 \u2502 0.89984 \u2502 \u2502 typo-orig-model \u2502 0.79419 \u2502 0.82945 \u2502 0.79419 \u2502 0.80266 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Feedback \u00b6 This project is part of ongoing research. In general NLP algorithms have proven to be brittle against typos and we wanted to make it easy for our community to investigate this. Feedback on the tool, as well as any interesting typo-related findings, is much appreciated. Feel free to mention any bugs on Github and any other feedback on the rasa forum . You can poke @koaning on the Rasa forum if you have any typo-related insights. Especially insights from non-English languages would be much appreciated!","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"The original goal of taipo was to augment NLU data such that we can train Rasa models to be robust against misspellings. This guide will show you how to train models that are robust against spelling errors.","title":"Getting Started"},{"location":"getting-started/#installation","text":"You can install this experiment via pip. python -m pip install \"taipo @ git+https://github.com/RasaHQ/taipo.git\" This will install the taipo command line interface in your virtualenv. You can confirm the installation went fine by running: python -m taipo","title":"Installation"},{"location":"getting-started/#generating-spelling-errors","text":"Let's say that you've gotten a Rasa project. Your folder structure would look something like: \ud83d\udcc2 rasa-project-dir \u2523\u2501\u2501 \ud83d\udcc2 actions \u2523\u2501\u2501 \ud83d\udcc2 data \u2503 \u2523\u2501\u2501 \ud83d\udcc4 nlu.yml \u2503 \u2523\u2501\u2501 \ud83d\udcc4 rules.yml \u2503 \u2517\u2501\u2501 \ud83d\udcc4 stories.yml \u2523\u2501\u2501 \ud83d\udcc2 models \u2523\u2501\u2501 \ud83d\udcc2 tests \u2523\u2501\u2501 \ud83d\udcc4 config.yml \u2523\u2501\u2501 \ud83d\udcc4 credentials.yml \u2523\u2501\u2501 \ud83d\udcc4 domain.yml \u2517\u2501\u2501 \ud83d\udcc4 endpoints.yml The idea is that we will generate a variant of nlu.yml that contains spelling errors. This way, we might be able to train our models to be robust against it. A straightforward way to do this is via; python -m taipo keyboard augment data/nlu.yml data/typo-nlu.yml This will generate a new file that contains typos. \ud83d\udcc2 rasa-project-dir \u2523\u2501\u2501 \ud83d\udcc2 actions \u2523\u2501\u2501 \ud83d\udcc2 data \u2503 \u2523\u2501\u2501 \ud83d\udcc4 nlu.yml \u2503 \u2523\u2501\u2501 \ud83d\udcc4 typo-nlu.yml \u2503 \u2523\u2501\u2501 \ud83d\udcc4 rules.yml \u2503 \u2517\u2501\u2501 \ud83d\udcc4 stories.yml \u2523\u2501\u2501 \ud83d\udcc2 models \u2523\u2501\u2501 \ud83d\udcc2 tests \u2523\u2501\u2501 \ud83d\udcc4 config.yml \u2523\u2501\u2501 \ud83d\udcc4 credentials.yml \u2523\u2501\u2501 \ud83d\udcc4 domain.yml \u2517\u2501\u2501 \ud83d\udcc4 endpoints.yml When you inspect the typo-nlu.yml file you'll notice that we copied each example from the original nlu.yml file but added some typos. These typos are based on the keyboard layout. The base setting assumes the US layout but you can configure some non-English layouts as well. Check the API docs for more info. When you now train your nlu model, it will also train on these misspelled items. python -m rasa train You will notice that training takes a fair bit longer because we're training on twice as much data now.","title":"Generating Spelling Errors"},{"location":"getting-started/#finetuning","text":"If you're worried about the long training time, you may prefer to use the fine-tuning feature instead. If you're unfamiliar with the technique, you may appreciate this algorithm whiteboard video. To train the system with finetuning you can first train your NLU model on the original data. rasa train nlu --nlu nlu/nlu.yml --fixed-model-name orig Once this model is trained, you can finetune it on the misspelled data. rasa train nlu --nlu nlu/nlu.yml \\ --finetune models/orig.tar.gz \\ --epoch-fraction 0.1 \\ --fixed-model-name finetuned","title":"Finetuning"},{"location":"getting-started/#benchmarking","text":"Training against misspelled data is nice, but we'd also like to quantify the effect that typos have on our system. This guide assumes that you have a tests/nlu-valid.yml file which can be used as a validation dataset. Let's make a misspelled variant of this dataset first. python -m taipo keyboard augment tests/nlu-valid.yml tests/typo-nlu-valid.yml We can now run our two models models/orig.tar.gz and models/finetuned.tar.gz against both of these datasets. rasa test nlu -u tests/nlu-valid.yml --model models/orig.tar.gz --out gridresults/orig-model rasa test nlu -u tests/nlu-valid.yml --model models/finetuned.tar.gz --out gridresults/finetuned-model rasa test nlu -u tests/typo-nlu-valid.yml --model models/orig.tar.gz --out gridresults/typo-orig-model rasa test nlu -u tests/typo-nlu-valid.yml --model models/finetuned.tar.gz --out gridresults/typo-finetuned-model This results in 4 folders that contain your benchmarked results. You could use rasalit to visualise these but you can also use a utility function from the command line. Let's say that you've got a folder structure like so: \ud83d\udcc2 gridresults \u2523\u2501\u2501 \ud83d\udcc2 orig-model \u2503 \u2523\u2501\u2501 ... \u2503 \u2517\u2501\u2501 \ud83d\udcc4 intent_report.json \u2523\u2501\u2501 \ud83d\udcc2 finetuned-model \u2503 \u2523\u2501\u2501 ... \u2503 \u2517\u2501\u2501 \ud83d\udcc4 intent_report.json \u2523\u2501\u2501 \ud83d\udcc2 typo-orig-model \u2503 \u2523\u2501\u2501 ... \u2503 \u2517\u2501\u2501 \ud83d\udcc4 intent_report.json \u2517\u2501\u2501 \ud83d\udcc2 typo-finetuned-model \u2523\u2501\u2501 ... \u2517\u2501\u2501 \ud83d\udcc4 intent_report.json Then you can get a convenient summary via: python -m taipo util summary gridresults You may get a table that looks like this: \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 folder \u2503 accuracy \u2503 precision \u2503 recall \u2503 f1 \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 finetuned-model \u2502 0.9022 \u2502 0.90701 \u2502 0.9022 \u2502 0.90265 \u2502 \u2502 orig-model \u2502 0.90018 \u2502 0.90972 \u2502 0.90018 \u2502 0.90192 \u2502 \u2502 typo-finetuned-model \u2502 0.89965 \u2502 0.90302 \u2502 0.89965 \u2502 0.89984 \u2502 \u2502 typo-orig-model \u2502 0.79419 \u2502 0.82945 \u2502 0.79419 \u2502 0.80266 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Benchmarking"},{"location":"getting-started/#feedback","text":"This project is part of ongoing research. In general NLP algorithms have proven to be brittle against typos and we wanted to make it easy for our community to investigate this. Feedback on the tool, as well as any interesting typo-related findings, is much appreciated. Feel free to mention any bugs on Github and any other feedback on the rasa forum . You can poke @koaning on the Rasa forum if you have any typo-related insights. Especially insights from non-English languages would be much appreciated!","title":"Feedback"},{"location":"api/confirm/","text":"taipo confirm \u00b6 > python -m taipo confirm --help Confirm labels inside of nlu.yml files. Options: --help Show this message and exit. Commands: logistic Confirm via basic sklearn pipeline. rasa-model Confirm via trained Rasa pipeline. taipo keyboard logistic \u00b6 This command trains a basic countvector model and runs it against one of your nlu.yml files. > taipo keyboard logistic --help Usage: confirm logistic [OPTIONS] MODEL_PATH NLU_PATH [OUT_PATH] Confirm via basic sklearn pipeline. Arguments: NLU_PATH The original nlu.yml file [required] [OUT_PATH] Path to write examples file to [default: checkthese.csv] Options: --help Show this message and exit. The idea is that any intents that the model got wrong are interesting candidates to double-check. There may be some confusing/incorrectly labelled examples in your data. Example Usage \u00b6 This command will take the nlu.yml file, train a pipeline based on it which it will then use to try to find bad labels. Any wrongly classifier examples will be saved in the checkthese.csv file. > python -m taipo confirm logistic nlu.yml checkthese.csv The checkthese.csv file also contains a confidence level, indicating the confidence that the model had while making the prediction. When a model shows high confidence on a wrong label, it deserves priority. taipo keyboard rasa-model \u00b6 This command takes a pretrained Rasa model and runs it against one of your nlu.yml files. > taipo keyboard rasa-model --help Usage: confirm rasa-model [OPTIONS] MODEL_PATH NLU_PATH [OUT_PATH] Confirm via trained Rasa pipeline. Arguments: MODEL_PATH Location of Rasa model. [required] NLU_PATH The original nlu.yml file [required] [OUT_PATH] Path to write examples file to [default: checkthese.csv] Options: --help Show this message and exit. The idea is that any intents that the model got wrong are interesting candidates to double-check. There may be some confusing/incorrectly labelled examples in your data. Example Usage \u00b6 This command will take the model.tar.gz model file and run it against the nlu.yml file. Any wrongly classifier examples will be saved in the checkthese.csv file. > python -m taipo confirm nlu.yml model.tar.gz checkthese.csv The checkthese.csv file also contains a confidence level, indicating the confidence that the model had while making the prediction. When a model shows high confidence on a wrong label, it deserves priority.","title":"confirm"},{"location":"api/confirm/#taipo-confirm","text":"> python -m taipo confirm --help Confirm labels inside of nlu.yml files. Options: --help Show this message and exit. Commands: logistic Confirm via basic sklearn pipeline. rasa-model Confirm via trained Rasa pipeline.","title":"taipo confirm"},{"location":"api/confirm/#taipo-keyboard-logistic","text":"This command trains a basic countvector model and runs it against one of your nlu.yml files. > taipo keyboard logistic --help Usage: confirm logistic [OPTIONS] MODEL_PATH NLU_PATH [OUT_PATH] Confirm via basic sklearn pipeline. Arguments: NLU_PATH The original nlu.yml file [required] [OUT_PATH] Path to write examples file to [default: checkthese.csv] Options: --help Show this message and exit. The idea is that any intents that the model got wrong are interesting candidates to double-check. There may be some confusing/incorrectly labelled examples in your data.","title":"taipo keyboard logistic"},{"location":"api/confirm/#example-usage","text":"This command will take the nlu.yml file, train a pipeline based on it which it will then use to try to find bad labels. Any wrongly classifier examples will be saved in the checkthese.csv file. > python -m taipo confirm logistic nlu.yml checkthese.csv The checkthese.csv file also contains a confidence level, indicating the confidence that the model had while making the prediction. When a model shows high confidence on a wrong label, it deserves priority.","title":"Example Usage"},{"location":"api/confirm/#taipo-keyboard-rasa-model","text":"This command takes a pretrained Rasa model and runs it against one of your nlu.yml files. > taipo keyboard rasa-model --help Usage: confirm rasa-model [OPTIONS] MODEL_PATH NLU_PATH [OUT_PATH] Confirm via trained Rasa pipeline. Arguments: MODEL_PATH Location of Rasa model. [required] NLU_PATH The original nlu.yml file [required] [OUT_PATH] Path to write examples file to [default: checkthese.csv] Options: --help Show this message and exit. The idea is that any intents that the model got wrong are interesting candidates to double-check. There may be some confusing/incorrectly labelled examples in your data.","title":"taipo keyboard rasa-model"},{"location":"api/confirm/#example-usage_1","text":"This command will take the model.tar.gz model file and run it against the nlu.yml file. Any wrongly classifier examples will be saved in the checkthese.csv file. > python -m taipo confirm nlu.yml model.tar.gz checkthese.csv The checkthese.csv file also contains a confidence level, indicating the confidence that the model had while making the prediction. When a model shows high confidence on a wrong label, it deserves priority.","title":"Example Usage"},{"location":"api/keyboard/","text":"taipo keyboard \u00b6 > python -m taipo keyboard Commands to simulate keyboard typos. Options: --help Show this message and exit. Commands: augment Applies typos to an NLU file and saves it to disk. generate Generate train/validation data with/without misspelling. These tools are able to simulate keyboard typos. It uses nlpaug as a backend and supports keyboard layouts of 10 languages ( de , en , es , fr , he , it , nl , pl , th , uk ). For more details on the mapping see here . taipo keyboard augment \u00b6 The augment command generates a single misspelled NLU file. python -m taipo keyboard augment --help Usage: keyboard augment [OPTIONS] FILE OUT Applies typos to an NLU file and saves it to disk. Arguments: FILE The original nlu.yml file [required] OUT Path to write misspelled file to [required] Options: --char-max INTEGER Max number of chars to change per line [default: 3] --word-max INTEGER Max number of words to change per line [default: 3] --lang TEXT Language for keyboard layout [default: en] --seed-aug INTEGER The seed value to augment the data --help Show this message and exit. Example Usage \u00b6 This example generates a new bad-spelling-nlu.yml file from nlu.yml . python -m taipo keyboard augment data/nlu.yml data/bad-spelling-nlu.yml This example generates does the same thing but assumes a Dutch keyboard layout. python -m taipo keyboard augment data/nlu.yml data/bad-spelling-nlu.yml --lang nl taipo keyboard generate \u00b6 The generate command takes a single NLU file and populates your data/test folders with relevant files to run benchmarks. Will also perform train/validation splitting. > python -m taipo keyboard generate --help Usage: keyboard generate [OPTIONS] FILE Generate train/validation data with/without misspelling. Will also generate files for the `/test` directory. Arguments: FILE The original nlu.yml file [required] Options: --seed-split INTEGER The seed value to split the data [default: 42] --seed-aug INTEGER The seed value to augment the data --test-size INTEGER Percentage of data to keep as test data [default: 33] --prefix TEXT Prefix to add to all the files [default: misspelled] --char-max INTEGER Max number of chars to change per line [default: 3] --word-max INTEGER Max number of words to change per line [default: 3] --lang TEXT Language for keyboard layout [default: en] --help Show this message and exit. Example Usage \u00b6 This command will take the original nlu-orig.yml file and will use it to populate the /test and /data folders. > python -m taipo keyboard generate data/nlu-orig.yml The current disk state is now: \ud83d\udcc2 rasa-project \u2523\u2501\u2501 \ud83d\udcc2 data \u2503 \u2523\u2501\u2501 \ud83d\udcc4 nlu-train.yml ( 667 items) \u2503 \u2517\u2501\u2501 \ud83d\udcc4 misspelled-nlu-train.yml ( 667 items) \u2523\u2501\u2501 \ud83d\udcc2 tests \u2503 \u2523\u2501\u2501 \ud83d\udcc4 nlu-valid.yml ( 333 items) \u2503 \u2517\u2501\u2501 \ud83d\udcc4 misspelled-nlu-valid.yml ( 333 items) \u2517\u2501\u2501 \ud83d\udcc4 nlu-orig.yml (1000 items)","title":"keyboard"},{"location":"api/keyboard/#taipo-keyboard","text":"> python -m taipo keyboard Commands to simulate keyboard typos. Options: --help Show this message and exit. Commands: augment Applies typos to an NLU file and saves it to disk. generate Generate train/validation data with/without misspelling. These tools are able to simulate keyboard typos. It uses nlpaug as a backend and supports keyboard layouts of 10 languages ( de , en , es , fr , he , it , nl , pl , th , uk ). For more details on the mapping see here .","title":"taipo keyboard"},{"location":"api/keyboard/#taipo-keyboard-augment","text":"The augment command generates a single misspelled NLU file. python -m taipo keyboard augment --help Usage: keyboard augment [OPTIONS] FILE OUT Applies typos to an NLU file and saves it to disk. Arguments: FILE The original nlu.yml file [required] OUT Path to write misspelled file to [required] Options: --char-max INTEGER Max number of chars to change per line [default: 3] --word-max INTEGER Max number of words to change per line [default: 3] --lang TEXT Language for keyboard layout [default: en] --seed-aug INTEGER The seed value to augment the data --help Show this message and exit.","title":"taipo keyboard augment"},{"location":"api/keyboard/#example-usage","text":"This example generates a new bad-spelling-nlu.yml file from nlu.yml . python -m taipo keyboard augment data/nlu.yml data/bad-spelling-nlu.yml This example generates does the same thing but assumes a Dutch keyboard layout. python -m taipo keyboard augment data/nlu.yml data/bad-spelling-nlu.yml --lang nl","title":"Example Usage"},{"location":"api/keyboard/#taipo-keyboard-generate","text":"The generate command takes a single NLU file and populates your data/test folders with relevant files to run benchmarks. Will also perform train/validation splitting. > python -m taipo keyboard generate --help Usage: keyboard generate [OPTIONS] FILE Generate train/validation data with/without misspelling. Will also generate files for the `/test` directory. Arguments: FILE The original nlu.yml file [required] Options: --seed-split INTEGER The seed value to split the data [default: 42] --seed-aug INTEGER The seed value to augment the data --test-size INTEGER Percentage of data to keep as test data [default: 33] --prefix TEXT Prefix to add to all the files [default: misspelled] --char-max INTEGER Max number of chars to change per line [default: 3] --word-max INTEGER Max number of words to change per line [default: 3] --lang TEXT Language for keyboard layout [default: en] --help Show this message and exit.","title":"taipo keyboard generate"},{"location":"api/keyboard/#example-usage_1","text":"This command will take the original nlu-orig.yml file and will use it to populate the /test and /data folders. > python -m taipo keyboard generate data/nlu-orig.yml The current disk state is now: \ud83d\udcc2 rasa-project \u2523\u2501\u2501 \ud83d\udcc2 data \u2503 \u2523\u2501\u2501 \ud83d\udcc4 nlu-train.yml ( 667 items) \u2503 \u2517\u2501\u2501 \ud83d\udcc4 misspelled-nlu-train.yml ( 667 items) \u2523\u2501\u2501 \ud83d\udcc2 tests \u2503 \u2523\u2501\u2501 \ud83d\udcc4 nlu-valid.yml ( 333 items) \u2503 \u2517\u2501\u2501 \ud83d\udcc4 misspelled-nlu-valid.yml ( 333 items) \u2517\u2501\u2501 \ud83d\udcc4 nlu-orig.yml (1000 items)","title":"Example Usage"},{"location":"api/translit/","text":"taipo translit \u00b6 > python -m taipo translit Commands to generate transliterations. Options: --help Show this message and exit. Commands: augment Applies translitertion to an NLU file and saves it to disk. generate Generate train/validation data with/without translitertion. These tools are able to transliterate to and from a latin alphabet. It uses transliterate as a backend and supports ( ru , mn , sr , bg , ka , uk , el , mk , l1 , hy ). taipo translit augment \u00b6 Transliterates a single NLU file to and from a latin alphabet. > python -m taipo translit augment --help Applies translitertion to an NLU file and saves it to disk. Arguments: FILE The original nlu.yml file [required] OUT Path to write misspelled file to [required] Options: --target TEXT Alphabet to map to. [default: latin] --source TEXT Alphabet to map from. [default: latin] --lang TEXT Language for keyboard layout [default: en] --help Show this message and exit. Example Usage \u00b6 This example generates a new greek-nlu.yml file from nlu.yml . python -m taipo keyboard augment data/nlu.yml data/greek-nlu.yml --target el This example generates works the other way around. It assumes a Greek alphabet as a starting point and transliterates it to the latin alphabet. python -m taipo keyboard augment data/greek-nlu.yml data/latin-nlu.yml --source el taipo translit generate \u00b6 The generate command takes a single NLU file and populates your data/test folders with relevant files to run benchmarks. Will also perform train/validation splitting. > python -m taipo translit generate --help Generate train/validation data with/without translitertion. Will also generate files for the `/test` directory. Arguments: FILE The original nlu.yml file [required] Options: --seed INTEGER The seed value to split the data [default: 42] --test-size INTEGER Percentage of data to keep as test data [default: 33] --prefix TEXT Prefix to add to all the files [default: translit] --target TEXT Alphabet to map to. [default: latin] --source TEXT Alphabet to map from. [default: latin] --lang TEXT Language for keyboard layout [default: en] --help Show this message and exit. Example Usage \u00b6 This command will take the original nlu-orig.yml file and will use it to populate the /test and /data folders. In this case it will generate characters from the Greek alphabet. > python -m taipo translit generate data/nlu-orig.yml --prefix greek --target el The following files will now be on disk. \ud83d\udcc2 rasa-project \u2523\u2501\u2501 \ud83d\udcc2 data \u2503 \u2523\u2501\u2501 \ud83d\udcc4 nlu-train.yml ( 667 items) \u2503 \u2517\u2501\u2501 \ud83d\udcc4 greek-nlu-train.yml ( 667 items) \u2523\u2501\u2501 \ud83d\udcc2 tests \u2503 \u2523\u2501\u2501 \ud83d\udcc4 nlu-valid.yml ( 333 items) \u2503 \u2517\u2501\u2501 \ud83d\udcc4 greek-nlu-valid.yml ( 333 items) \u2517\u2501\u2501 \ud83d\udcc4 nlu-orig.yml (1000 items)","title":"translit"},{"location":"api/translit/#taipo-translit","text":"> python -m taipo translit Commands to generate transliterations. Options: --help Show this message and exit. Commands: augment Applies translitertion to an NLU file and saves it to disk. generate Generate train/validation data with/without translitertion. These tools are able to transliterate to and from a latin alphabet. It uses transliterate as a backend and supports ( ru , mn , sr , bg , ka , uk , el , mk , l1 , hy ).","title":"taipo translit"},{"location":"api/translit/#taipo-translit-augment","text":"Transliterates a single NLU file to and from a latin alphabet. > python -m taipo translit augment --help Applies translitertion to an NLU file and saves it to disk. Arguments: FILE The original nlu.yml file [required] OUT Path to write misspelled file to [required] Options: --target TEXT Alphabet to map to. [default: latin] --source TEXT Alphabet to map from. [default: latin] --lang TEXT Language for keyboard layout [default: en] --help Show this message and exit.","title":"taipo translit augment"},{"location":"api/translit/#example-usage","text":"This example generates a new greek-nlu.yml file from nlu.yml . python -m taipo keyboard augment data/nlu.yml data/greek-nlu.yml --target el This example generates works the other way around. It assumes a Greek alphabet as a starting point and transliterates it to the latin alphabet. python -m taipo keyboard augment data/greek-nlu.yml data/latin-nlu.yml --source el","title":"Example Usage"},{"location":"api/translit/#taipo-translit-generate","text":"The generate command takes a single NLU file and populates your data/test folders with relevant files to run benchmarks. Will also perform train/validation splitting. > python -m taipo translit generate --help Generate train/validation data with/without translitertion. Will also generate files for the `/test` directory. Arguments: FILE The original nlu.yml file [required] Options: --seed INTEGER The seed value to split the data [default: 42] --test-size INTEGER Percentage of data to keep as test data [default: 33] --prefix TEXT Prefix to add to all the files [default: translit] --target TEXT Alphabet to map to. [default: latin] --source TEXT Alphabet to map from. [default: latin] --lang TEXT Language for keyboard layout [default: en] --help Show this message and exit.","title":"taipo translit generate"},{"location":"api/translit/#example-usage_1","text":"This command will take the original nlu-orig.yml file and will use it to populate the /test and /data folders. In this case it will generate characters from the Greek alphabet. > python -m taipo translit generate data/nlu-orig.yml --prefix greek --target el The following files will now be on disk. \ud83d\udcc2 rasa-project \u2523\u2501\u2501 \ud83d\udcc2 data \u2503 \u2523\u2501\u2501 \ud83d\udcc4 nlu-train.yml ( 667 items) \u2503 \u2517\u2501\u2501 \ud83d\udcc4 greek-nlu-train.yml ( 667 items) \u2523\u2501\u2501 \ud83d\udcc2 tests \u2503 \u2523\u2501\u2501 \ud83d\udcc4 nlu-valid.yml ( 333 items) \u2503 \u2517\u2501\u2501 \ud83d\udcc4 greek-nlu-valid.yml ( 333 items) \u2517\u2501\u2501 \ud83d\udcc4 nlu-orig.yml (1000 items)","title":"Example Usage"},{"location":"api/util/","text":"taipo util \u00b6 > python -m taipo util Some utility commands. Options: --help Show this message and exit. Commands: csv-to-yml Turns a .csv file into nlu.yml for Rasa yml-to-csv Turns a nlu.yml file into .csv summary Displays summary tables for gridsearch results. We host some utility methods to transform intent-based data from .csv to .yml. Be aware, these methods ignore entities! taipo util csv-to-yml \u00b6 > python -m taipo util csv-to-yml --help Usage: util csv-to-yml [OPTIONS] FILE Turns a .csv file into nlu.yml for Rasa Arguments: FILE The csv file to convert [required] Options: --out PATH The path of the output file. [default: .] --text-col TEXT Name of the text column. [default: text] --label-col TEXT Name of the label column. [default: intent] --help Show this message and exit. taipo util yml-to-csv \u00b6 > python -m taipo util csv-to-yml --help Usage: __main__.py util yml-to-csv [OPTIONS] FILE Turns a nlu.yml file into .csv Arguments: FILE The csv file to convert [required] Options: --out PATH The path of the output file. [default: .] --help Show this message and exit. taipo util summary \u00b6 Usage: __main__.py util summary [OPTIONS] FOLDER Displays summary tables for gridsearch results. Arguments: FOLDER Folder that contains grid-result folders. [required] Options: --help Show this message and exit. Example Usage \u00b6 Let's say that you've got a folder structure like so: \ud83d\udcc2 gridresults \u2523\u2501\u2501 \ud83d\udcc2 orig-model \u2503 \u2523\u2501\u2501 ... \u2503 \u2517\u2501\u2501 \ud83d\udcc4 intent_report.json \u2523\u2501\u2501 \ud83d\udcc2 finetuned-model \u2503 \u2523\u2501\u2501 ... \u2503 \u2517\u2501\u2501 \ud83d\udcc4 intent_report.json \u2523\u2501\u2501 \ud83d\udcc2 typo-orig-model \u2503 \u2523\u2501\u2501 ... \u2503 \u2517\u2501\u2501 \ud83d\udcc4 intent_report.json \u2517\u2501\u2501 \ud83d\udcc2 typo-finetuned-model \u2523\u2501\u2501 ... \u2517\u2501\u2501 \ud83d\udcc4 intent_report.json Then you can get a convenient summary via: python -m taipo util summary gridresults You may get a table that looks like this: \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 folder \u2503 accuracy \u2503 precision \u2503 recall \u2503 f1 \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 finetuned-model \u2502 0.9022 \u2502 0.90701 \u2502 0.9022 \u2502 0.90265 \u2502 \u2502 orig-model \u2502 0.90018 \u2502 0.90972 \u2502 0.90018 \u2502 0.90192 \u2502 \u2502 typo-finetuned-model \u2502 0.89965 \u2502 0.90302 \u2502 0.89965 \u2502 0.89984 \u2502 \u2502 typo-orig-model \u2502 0.79419 \u2502 0.82945 \u2502 0.79419 \u2502 0.80266 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"util"},{"location":"api/util/#taipo-util","text":"> python -m taipo util Some utility commands. Options: --help Show this message and exit. Commands: csv-to-yml Turns a .csv file into nlu.yml for Rasa yml-to-csv Turns a nlu.yml file into .csv summary Displays summary tables for gridsearch results. We host some utility methods to transform intent-based data from .csv to .yml. Be aware, these methods ignore entities!","title":"taipo util"},{"location":"api/util/#taipo-util-csv-to-yml","text":"> python -m taipo util csv-to-yml --help Usage: util csv-to-yml [OPTIONS] FILE Turns a .csv file into nlu.yml for Rasa Arguments: FILE The csv file to convert [required] Options: --out PATH The path of the output file. [default: .] --text-col TEXT Name of the text column. [default: text] --label-col TEXT Name of the label column. [default: intent] --help Show this message and exit.","title":"taipo util csv-to-yml"},{"location":"api/util/#taipo-util-yml-to-csv","text":"> python -m taipo util csv-to-yml --help Usage: __main__.py util yml-to-csv [OPTIONS] FILE Turns a nlu.yml file into .csv Arguments: FILE The csv file to convert [required] Options: --out PATH The path of the output file. [default: .] --help Show this message and exit.","title":"taipo util yml-to-csv"},{"location":"api/util/#taipo-util-summary","text":"Usage: __main__.py util summary [OPTIONS] FOLDER Displays summary tables for gridsearch results. Arguments: FOLDER Folder that contains grid-result folders. [required] Options: --help Show this message and exit.","title":"taipo util summary"},{"location":"api/util/#example-usage","text":"Let's say that you've got a folder structure like so: \ud83d\udcc2 gridresults \u2523\u2501\u2501 \ud83d\udcc2 orig-model \u2503 \u2523\u2501\u2501 ... \u2503 \u2517\u2501\u2501 \ud83d\udcc4 intent_report.json \u2523\u2501\u2501 \ud83d\udcc2 finetuned-model \u2503 \u2523\u2501\u2501 ... \u2503 \u2517\u2501\u2501 \ud83d\udcc4 intent_report.json \u2523\u2501\u2501 \ud83d\udcc2 typo-orig-model \u2503 \u2523\u2501\u2501 ... \u2503 \u2517\u2501\u2501 \ud83d\udcc4 intent_report.json \u2517\u2501\u2501 \ud83d\udcc2 typo-finetuned-model \u2523\u2501\u2501 ... \u2517\u2501\u2501 \ud83d\udcc4 intent_report.json Then you can get a convenient summary via: python -m taipo util summary gridresults You may get a table that looks like this: \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 folder \u2503 accuracy \u2503 precision \u2503 recall \u2503 f1 \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 finetuned-model \u2502 0.9022 \u2502 0.90701 \u2502 0.9022 \u2502 0.90265 \u2502 \u2502 orig-model \u2502 0.90018 \u2502 0.90972 \u2502 0.90018 \u2502 0.90192 \u2502 \u2502 typo-finetuned-model \u2502 0.89965 \u2502 0.90302 \u2502 0.89965 \u2502 0.89984 \u2502 \u2502 typo-orig-model \u2502 0.79419 \u2502 0.82945 \u2502 0.79419 \u2502 0.80266 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Example Usage"}]}